# ğŸ§  RAG Chatbot

A simple Retrieval-Augmented Generation (RAG) chatbot that combines a local language model with a document-based knowledge base to provide contextual answers.

## ğŸ“š Overview

This project implements a question-answering chatbot using:

- ğŸ” **Document retrieval** (based on local PDFs or text files)
- ğŸ§  **Local LLM inference** using a `gguf` quantized model (e.g., TinyLlama)
- ğŸ—ƒï¸ **Vector database** with FAISS
- ğŸ–¥ï¸ **Gradio UI** for easy interaction

## ğŸ’¡ Motivation

The idea is to create a privacy-preserving assistant that can answer questions based on your own documents without relying on external APIs.

## ğŸ“ Project Structure

``` bash
rag_chatbot/
â”‚
â”œâ”€â”€ app.py # Gradio interface
â”œâ”€â”€ ingest.py # Script to load and embed documents
â”œâ”€â”€ chat.py # RAG pipeline logic
â”œâ”€â”€ utils.py # Helper functions
â”œâ”€â”€ models/ # Directory for your local .gguf model (excluded from Git)
â”œâ”€â”€ data/ # Your input documents (PDFs, text, etc.)
â”œâ”€â”€ db/ # FAISS index will be stored here
â”œâ”€â”€ README.md # This file
â””â”€â”€ requirements.txt # Python dependencies
```

## ğŸš€ How to Run

### 1. Clone the repository

``` bash
git clone https://github.com/erika-chang/rag_chatbot.git
cd rag_chatbot
```

### 2. Set up your environment
We recommend using a virtual environment:

``` bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```
### 3. Add your model
Place your .gguf model file in the models/ folder (not tracked by Git).
You can use a model like TinyLlama.

Example:

``` bash
models/
â””â”€â”€ tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
```

### 4. Add your documents
Put your custom documents (PDFs, TXTs, etc.) in the data/ folder.

``` bash
data/
â””â”€â”€ your-documents.pdf
```

### 5. Run ingestion

``` bash
python ingest.py
```

This will parse, split, and embed your documents, storing the vectors in a local FAISS database.

### 6. Start the chatbot

``` bash
python app.py
```

The Gradio interface will open in your browser at http://localhost:7860.

## ğŸ›‘ GitHub File Size Limit
The .gguf model is excluded from version control to respect GitHub's 100MB file size limit.
Make sure to add it manually to the models/ directory before running the app.

## ğŸ§¾ License
This project is open source and available under the MIT License.

Created by Erika Chang â€“ 2025
