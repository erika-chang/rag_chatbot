# ğŸ§  RAG Chatbot

A simple Retrieval-Augmented Generation (RAG) chatbot that combines a local language model with a document-based knowledge base to provide contextual answers.

## ğŸ“š Overview

This project implements a question-answering chatbot using:

- ğŸ” **Document retrieval** (based on local PDFs or text files)
- ğŸ§  **Local LLM inference** using a `gguf` quantized model (e.g., TinyLlama)
- ğŸ—ƒï¸ **Vector database** with FAISS
- ğŸ–¥ï¸ **Gradio UI** for easy interaction

## ğŸ’¡ Motivation

The idea is to create a privacy-preserving assistant that can answer questions based on your own documents without relying on external APIs.

## ğŸ“ Project Structure

``` bash
rag_chatbot/
â”‚
docs/
â”œâ”€â”€ refund_policy.txt
â”œâ”€â”€ shipping_info.txt
â””â”€â”€ product_faq.txt
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ mistral-7b-instruct-v0.1.Q4_K_M.gguf
â”‚
â”œâ”€â”€ chatbot.py
â””â”€â”€ requirements.txt

```

## ğŸš€ How to Run

### 1. Clone the repository

``` bash
git clone https://github.com/erika-chang/rag_chatbot.git
cd rag_chatbot
```

### 2. Set up your environment
We recommend using a virtual environment:

``` bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```
### 3. Start the chatbot

``` bash
python chatbot.py
```

## ğŸ›‘ GitHub File Size Limit
The .gguf model is excluded from version control to respect GitHub's 100MB file size limit.
Make sure to add it manually to the models/ directory before running the app.

## ğŸ§¾ License
This project is open source and available under the MIT License.

Created by Erika Chang â€“ 2025
